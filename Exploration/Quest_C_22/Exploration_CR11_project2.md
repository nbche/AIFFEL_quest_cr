# í”„ë¡œì íŠ¸ëª…: 2. ê±°ìš¸ì•„ ê±°ìš¸ì•„

í”„ë¡œì íŠ¸ ëª©ì°¨:

1.  Data Preparation
2.  CV model setting
3.  Traning & Result analysis (Case 1. ê¸°ë³¸ëª¨ë¸)
4.  Traning & Result analysis (Case 2. Data ì¡°ì •)
5.  Traning & Result analysis (Case 3. ì¶”ì¶œì¸µ ê°€ì¤‘ì¹˜ ë™ê²° í•´ì¡”)
6.  Traning & Result analysis (Case 4. í•™ìŠµë¥  ì†ì‹¤)
7.  Traning & Result analysis (Case 5. ê°€ì¤‘ì¹˜ ì†ì‹¤)
8.  ëª¨ë¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
9.  ëª¨ë¸ ìƒìš©í™” ì¤€ë¹„
10. í”ŒëŸ¬í„° ì•± ì‹¤ì—° (ì‹¤íŒ¨í•¨)
11. íšŒê³ 

# 1. Data Prepration


```python
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pathlib
import PIL
import PIL.Image
import shutil
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns

import tensorflow as tf
import tensorflow_addons as tfa
import tensorflow_datasets as tfds
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.callbacks import (
    ModelCheckpoint,     # ëª¨ë¸ ì €ì¥
    EarlyStopping,      # ì¡°ê¸° ì¢…ë£Œ
    ReduceLROnPlateau,  # í•™ìŠµë¥  ì¡°ì •
    TensorBoard,        # í…ì„œë³´ë“œ ë¡œê¹…
    CSVLogger,          # CSV íŒŒì¼ë¡œ ë¡œê·¸ ì €ì¥
    LearningRateScheduler # í•™ìŠµë¥  ìŠ¤ì¼€ì¥´ë¡œ ì‚¬ìš©
)
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.regularizers import l2
```


```python
# aiffel ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
base_dir = '/aiffel/aiffel/'
dataset_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"

# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
data_dir = tf.keras.utils.get_file(origin=dataset_url,
                                  fname='flower_photos',
                                  cache_dir=base_dir,  # aiffel ë””ë ‰í† ë¦¬ì— ì €ì¥
                                  untar=True)
data_dir = pathlib.Path(data_dir)

# ì €ì¥ëœ ê²½ë¡œ í™•ì¸
print(f"ë°ì´í„°ê°€ ì €ì¥ëœ ê²½ë¡œ: {data_dir}")

# ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
print("\ní´ë” êµ¬ì¡°:")
for item in data_dir.glob('*'):
    if item.is_dir():
        print(f"í´ë˜ìŠ¤: {item.name}")
        print(f"ì´ë¯¸ì§€ ê°œìˆ˜: {len(list(item.glob('*')))}ê°œ")

# ì´ë¯¸ì§€ ê°œìˆ˜
image_count = len(list(data_dir.glob('*/*.jpg')))
print(f"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {image_count}")
```

    ë°ì´í„°ê°€ ì €ì¥ëœ ê²½ë¡œ: /aiffel/aiffel/datasets/flower_photos
    
    í´ë” êµ¬ì¡°:
    í´ë˜ìŠ¤: dandelion
    ì´ë¯¸ì§€ ê°œìˆ˜: 898ê°œ
    í´ë˜ìŠ¤: sunflowers
    ì´ë¯¸ì§€ ê°œìˆ˜: 699ê°œ
    í´ë˜ìŠ¤: daisy
    ì´ë¯¸ì§€ ê°œìˆ˜: 633ê°œ
    í´ë˜ìŠ¤: tulips
    ì´ë¯¸ì§€ ê°œìˆ˜: 799ê°œ
    í´ë˜ìŠ¤: .ipynb_checkpoints
    ì´ë¯¸ì§€ ê°œìˆ˜: 0ê°œ
    í´ë˜ìŠ¤: roses
    ì´ë¯¸ì§€ ê°œìˆ˜: 641ê°œ
    ì´ ì´ë¯¸ì§€ ê°œìˆ˜: 3670



```python
# ì´ë¯¸ì§€ ì‹œê°í™”

def display_sample_images(data_dir, n_samples=5):
    # í´ë˜ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì •ë ¬ëœ ìƒíƒœë¡œ)
    classes = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])
    n_classes = len(classes)
    
    # figure í¬ê¸° ì„¤ì •
    plt.figure(figsize=(15, 3*n_classes))
    
    # ê° í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ í‘œì‹œ
    for idx, class_name in enumerate(classes):
        class_path = data_dir / class_name
        image_files = list(class_path.glob('*'))[:n_samples]
        
        for i, image_path in enumerate(image_files):
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = plt.imread(image_path)
            
            # subplot ìœ„ì¹˜ ê³„ì‚° (1ë¶€í„° ì‹œì‘í•˜ë„ë¡ ë³´ì¥)
            subplot_idx = idx * n_samples + i + 1
            
            # subplotì´ ìœ íš¨í•œ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
            if subplot_idx <= n_classes * n_samples:
                plt.subplot(n_classes, n_samples, subplot_idx)
                plt.imshow(img)
                plt.axis('off')
                
                # ì²« ë²ˆì§¸ ì—´ì—ë§Œ í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ
                if i == 0:
                    plt.title(f'{class_name}', pad=10)
    
    plt.tight_layout()
    plt.show()

# ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸ ë° ì‹œê°í™”
print(f"ë°ì´í„° ê²½ë¡œ: {data_dir}")
display_sample_images(data_dir)

# í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ ì¶œë ¥
for item in sorted(data_dir.glob('*')):
    if item.is_dir():
        print(f"{item.name}: {len(list(item.glob('*')))}ê°œ ì´ë¯¸ì§€")
```

    ë°ì´í„° ê²½ë¡œ: /aiffel/aiffel/datasets/flower_photos



    
![png](output_5_1.png)
    


    .ipynb_checkpoints: 0ê°œ ì´ë¯¸ì§€
    daisy: 633ê°œ ì´ë¯¸ì§€
    dandelion: 898ê°œ ì´ë¯¸ì§€
    roses: 641ê°œ ì´ë¯¸ì§€
    sunflowers: 699ê°œ ì´ë¯¸ì§€
    tulips: 799ê°œ ì´ë¯¸ì§€



```python
# ë°ì´í„° ì„¸íŠ¸ ì „ì²˜ë¦¬
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)
```


```python
# ë°ì´í„° ì„¸íŠ¸ ë§Œë“¤ê¸°

def split_dataset(source_dir, train_dir, valid_dir, test_dir, train_size=0.7, valid_size=0.15, test_size=0.15, random_state=42):
    print(f"\n===== ë°ì´í„° ë¶„í•  ì‹œì‘ =====")
    print(f"ë¶„í•  ë¹„ìœ¨: í›ˆë ¨={train_size*100}%, ê²€ì¦={valid_size*100}%, í…ŒìŠ¤íŠ¸={test_size*100}%")
    
    # ë¹„ìœ¨ ê²€ì‚¬
    if round(train_size + valid_size + test_size, 5) != 1.0:
        raise ValueError("train_size, valid_size, test_sizeì˜ í•©ì´ 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(valid_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)
    
    dataset_stats = {'train': {}, 'valid': {}, 'test': {}}
    
    # ìˆ¨ê¹€ íŒŒì¼ê³¼ ë””ë ‰í† ë¦¬ ì œì™¸
    for class_name in os.listdir(source_dir):
        # .ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ìˆ¨ê¹€ íŒŒì¼/í´ë” ë¬´ì‹œ
        if class_name.startswith('.'):
            continue
            
        class_dir = os.path.join(source_dir, class_name)
        if not os.path.isdir(class_dir):
            continue
            
        # í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
        os.makedirs(os.path.join(valid_dir, class_name), exist_ok=True)
        os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
        files = [f for f in os.listdir(class_dir) 
                if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif'))
                and not f.startswith('.')]  # ìˆ¨ê¹€ íŒŒì¼ ì œì™¸
        
        # ë¨¼ì € í…ŒìŠ¤íŠ¸ì…‹ ë¶„ë¦¬
        train_valid_files, test_files = train_test_split(
            files,
            test_size=test_size,
            random_state=random_state
        )
        
        # ë‚¨ì€ ë°ì´í„°ë¥¼ í›ˆë ¨ì…‹ê³¼ ê²€ì¦ì…‹ìœ¼ë¡œ ë¶„í• 
        # valid_sizeë¥¼ ë‚¨ì€ ë¹„ìœ¨ì— ë§ê²Œ ì¡°ì •
        remaining_valid_ratio = valid_size / (train_size + valid_size)
        train_files, valid_files = train_test_split(
            train_valid_files,
            test_size=remaining_valid_ratio,
            random_state=random_state
        )
        
        # íŒŒì¼ ë³µì‚¬ í•¨ìˆ˜
        def copy_files(file_list, target_dir):
            for f in file_list:
                src = os.path.join(source_dir, class_name, f)
                dst = os.path.join(target_dir, class_name, f)
                shutil.copy2(src, dst)
        
        # íŒŒì¼ ë³µì‚¬ ì‹¤í–‰
        copy_files(train_files, train_dir)
        copy_files(valid_files, valid_dir)
        copy_files(test_files, test_dir)
        
        # í†µê³„ ì €ì¥
        dataset_stats['train'][class_name] = len(train_files)
        dataset_stats['valid'][class_name] = len(valid_files)
        dataset_stats['test'][class_name] = len(test_files)
        
        print(f"\ní´ë˜ìŠ¤ {class_name}:")
        print(f"  - ì „ì²´ ì´ë¯¸ì§€: {len(files)}ê°œ")
        print(f"  - í›ˆë ¨ ì´ë¯¸ì§€: {len(train_files)}ê°œ ({len(train_files)/len(files)*100:.1f}%)")
        print(f"  - ê²€ì¦ ì´ë¯¸ì§€: {len(valid_files)}ê°œ ({len(valid_files)/len(files)*100:.1f}%)")
        print(f"  - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_files)}ê°œ ({len(test_files)/len(files)*100:.1f}%)")
    
   
    # ì „ì²´ í†µê³„ ì¶œë ¥
    print("\n===== ìµœì¢… ë°ì´í„° ë¶„í•  ê²°ê³¼ =====")
    total_train = sum(dataset_stats['train'].values())
    total_valid = sum(dataset_stats['valid'].values())
    total_test = sum(dataset_stats['test'].values())
    total_images = total_train + total_valid + total_test
    
    print(f"ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {total_images}ê°œ")
    print(f"í›ˆë ¨ì…‹: {total_train}ê°œ ({total_train/total_images*100:.1f}%)")
    print(f"ê²€ì¦ì…‹: {total_valid}ê°œ ({total_valid/total_images*100:.1f}%)")
    print(f"í…ŒìŠ¤íŠ¸ì…‹: {total_test}ê°œ ({total_test/total_images*100:.1f}%)")
    
    return dataset_stats

  
# ê²½ë¡œ ì„¤ì •
source_directory = '/aiffel/aiffel/datasets/flower_photos'
train_directory = '/aiffel/aiffel/datasets/flower_photos_split/train'
valid_directory = '/aiffel/aiffel/datasets/flower_photos_split/valid'
test_directory = '/aiffel/aiffel/datasets/flower_photos_split/test' 

# ë°ì´í„° ë¶„í•  ì‹¤í–‰
stats = split_dataset(source_directory, train_directory, valid_directory, test_directory)
```

    
    ===== ë°ì´í„° ë¶„í•  ì‹œì‘ =====
    ë¶„í•  ë¹„ìœ¨: í›ˆë ¨=70.0%, ê²€ì¦=15.0%, í…ŒìŠ¤íŠ¸=15.0%
    
    í´ë˜ìŠ¤ dandelion:
      - ì „ì²´ ì´ë¯¸ì§€: 898ê°œ
      - í›ˆë ¨ ì´ë¯¸ì§€: 628ê°œ (69.9%)
      - ê²€ì¦ ì´ë¯¸ì§€: 135ê°œ (15.0%)
      - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: 135ê°œ (15.0%)
    
    í´ë˜ìŠ¤ sunflowers:
      - ì „ì²´ ì´ë¯¸ì§€: 699ê°œ
      - í›ˆë ¨ ì´ë¯¸ì§€: 489ê°œ (70.0%)
      - ê²€ì¦ ì´ë¯¸ì§€: 105ê°œ (15.0%)
      - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: 105ê°œ (15.0%)
    
    í´ë˜ìŠ¤ daisy:
      - ì „ì²´ ì´ë¯¸ì§€: 633ê°œ
      - í›ˆë ¨ ì´ë¯¸ì§€: 443ê°œ (70.0%)
      - ê²€ì¦ ì´ë¯¸ì§€: 95ê°œ (15.0%)
      - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: 95ê°œ (15.0%)
    
    í´ë˜ìŠ¤ tulips:
      - ì „ì²´ ì´ë¯¸ì§€: 799ê°œ
      - í›ˆë ¨ ì´ë¯¸ì§€: 559ê°œ (70.0%)
      - ê²€ì¦ ì´ë¯¸ì§€: 120ê°œ (15.0%)
      - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: 120ê°œ (15.0%)
    
    í´ë˜ìŠ¤ roses:
      - ì „ì²´ ì´ë¯¸ì§€: 641ê°œ
      - í›ˆë ¨ ì´ë¯¸ì§€: 448ê°œ (69.9%)
      - ê²€ì¦ ì´ë¯¸ì§€: 96ê°œ (15.0%)
      - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: 97ê°œ (15.1%)
    
    ===== ìµœì¢… ë°ì´í„° ë¶„í•  ê²°ê³¼ =====
    ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: 3670ê°œ
    í›ˆë ¨ì…‹: 2567ê°œ (69.9%)
    ê²€ì¦ì…‹: 551ê°œ (15.0%)
    í…ŒìŠ¤íŠ¸ì…‹: 552ê°œ (15.0%)



```python
# ë°ì´í„° ì œë„ˆë ˆì´í„° ì„¤ì •

## ê²½ë¡œ ì •ì˜
train_dir = '/aiffel/aiffel/datasets/flower_photos_split/train'
valid_dir = '/aiffel/aiffel/datasets/flower_photos_split/valid'
test_dir = '/aiffel/aiffel/datasets/flower_photos_split/test'

## .ipynb_checkpoints í´ë” ì œê±°
for dir_path in [train_dir, valid_dir, test_dir]:
    checkpoint_path = os.path.join(dir_path, '.ipynb_checkpoints')
    if os.path.exists(checkpoint_path):
        shutil.rmtree(checkpoint_path)

## ë°ì´í„° ì œë„ˆë ˆì´í„° ì„¤ì •        
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

valid_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

# 2. ë°ì´í„° ë¡œë“œ ë° í´ë˜ìŠ¤ í™•ì¸
train_generator = train_datagen.flow_from_directory(
    directory='/aiffel/aiffel/datasets/flower_photos_split/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=True
)

valid_generator = valid_datagen.flow_from_directory(
    directory='/aiffel/aiffel/datasets/flower_photos_split/valid',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    directory='/aiffel/aiffel/datasets/flower_photos_split/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# 3. í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
print("í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤:", train_generator.class_indices)
print("ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤:", valid_generator.class_indices)
print("í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤:", test_generator.class_indices)

num_classes = len(train_generator.class_indices)
print("í´ë˜ìŠ¤ ìˆ˜:", num_classes)
```

    Found 2567 images belonging to 5 classes.
    Found 551 images belonging to 5 classes.
    Found 552 images belonging to 5 classes.
    í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤: {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}
    ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤: {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}
    í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤: {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}
    í´ë˜ìŠ¤ ìˆ˜: 5


# 2. CV model setting


```python
# ëª¨ë¸ ìƒì„±
def create_model(num_classes):
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu')(x)
    predictions = Dense(num_classes, activation='softmax')(x)
    
    model = Model(inputs=base_model.input, outputs=predictions)
    
    # ê¸°ë³¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³ ì •
    for layer in base_model.layers:
        layer.trainable = False
    
    return model

# ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼
model = create_model(num_classes)
model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# ëª¨ë¸ êµ¬ì¡° í™•ì¸
model.summary()

# ì²´í¬í¬ì¸íŠ¸ì™€ ë¡œê·¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
checkpoint_path = "model_checkpoints"
log_path = "training_logs"
os.makedirs(checkpoint_path, exist_ok=True)
os.makedirs(log_path, exist_ok=True)

# ì½œë°± ì •ì˜
callbacks = [
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    ModelCheckpoint(
        filepath=os.path.join(checkpoint_path, 'vgg16_case1.h5'),
        monitor='val_accuracy',    # ê²€ì¦ ì •í™•ë„ ëª¨ë‹ˆí„°ë§
        save_best_only=True,      # ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ë§Œ ì €ì¥
        mode='max',               # ì •í™•ë„ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        verbose=1
    ),
    
    # ì¡°ê¸° ì¢…ë£Œ
    EarlyStopping(
        monitor='val_loss',       # ê²€ì¦ ì†ì‹¤ ëª¨ë‹ˆí„°ë§
        patience=5,               # 5ë²ˆì˜ ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ì§€
        restore_best_weights=True,# ê°€ì¥ ì¢‹ì€ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
        verbose=1
    ),
 
]
```

    Model: "model_3"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_4 (InputLayer)         [(None, 224, 224, 3)]     0         
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         
    _________________________________________________________________
    global_average_pooling2d_3 ( (None, 512)               0         
    _________________________________________________________________
    dense_6 (Dense)              (None, 512)               262656    
    _________________________________________________________________
    dense_7 (Dense)              (None, 5)                 2565      
    =================================================================
    Total params: 14,979,909
    Trainable params: 265,221
    Non-trainable params: 14,714,688
    _________________________________________________________________


# 3. Traning & Result analysis (Case 1. ê¸°ë³¸ëª¨ë¸)


```python
history_1_0 = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=50,
    callbacks=callbacks,
    verbose=1
)
```

    Epoch 1/50
    81/81 [==============================] - 37s 448ms/step - loss: 1.5919 - accuracy: 0.5551 - val_loss: 1.0314 - val_accuracy: 0.7078
    
    Epoch 00001: val_accuracy improved from -inf to 0.70780, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 2/50
    81/81 [==============================] - 36s 445ms/step - loss: 0.6598 - accuracy: 0.7865 - val_loss: 0.7944 - val_accuracy: 0.7677
    
    Epoch 00002: val_accuracy improved from 0.70780 to 0.76770, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 3/50
    81/81 [==============================] - 36s 443ms/step - loss: 0.5241 - accuracy: 0.8196 - val_loss: 0.6997 - val_accuracy: 0.7840
    
    Epoch 00003: val_accuracy improved from 0.76770 to 0.78403, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 4/50
    81/81 [==============================] - 36s 444ms/step - loss: 0.4062 - accuracy: 0.8578 - val_loss: 0.6709 - val_accuracy: 0.8094
    
    Epoch 00004: val_accuracy improved from 0.78403 to 0.80944, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 5/50
    81/81 [==============================] - 36s 444ms/step - loss: 0.3502 - accuracy: 0.8785 - val_loss: 0.6422 - val_accuracy: 0.8131
    
    Epoch 00005: val_accuracy improved from 0.80944 to 0.81307, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 6/50
    81/81 [==============================] - 36s 442ms/step - loss: 0.3119 - accuracy: 0.8839 - val_loss: 0.5862 - val_accuracy: 0.8276
    
    Epoch 00006: val_accuracy improved from 0.81307 to 0.82759, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 7/50
    81/81 [==============================] - 37s 456ms/step - loss: 0.2720 - accuracy: 0.8991 - val_loss: 0.5698 - val_accuracy: 0.8348
    
    Epoch 00007: val_accuracy improved from 0.82759 to 0.83485, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 8/50
    81/81 [==============================] - 37s 450ms/step - loss: 0.2400 - accuracy: 0.9104 - val_loss: 0.5374 - val_accuracy: 0.8421
    
    Epoch 00008: val_accuracy improved from 0.83485 to 0.84211, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 9/50
    81/81 [==============================] - 36s 445ms/step - loss: 0.2317 - accuracy: 0.9162 - val_loss: 0.5482 - val_accuracy: 0.8330
    
    Epoch 00009: val_accuracy did not improve from 0.84211
    Epoch 10/50
    81/81 [==============================] - 36s 447ms/step - loss: 0.2063 - accuracy: 0.9229 - val_loss: 0.5250 - val_accuracy: 0.8457
    
    Epoch 00010: val_accuracy improved from 0.84211 to 0.84574, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 11/50
    81/81 [==============================] - 37s 455ms/step - loss: 0.1916 - accuracy: 0.9330 - val_loss: 0.5294 - val_accuracy: 0.8457
    
    Epoch 00011: val_accuracy did not improve from 0.84574
    Epoch 12/50
    81/81 [==============================] - 37s 450ms/step - loss: 0.1709 - accuracy: 0.9420 - val_loss: 0.5034 - val_accuracy: 0.8548
    
    Epoch 00012: val_accuracy improved from 0.84574 to 0.85481, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 13/50
    81/81 [==============================] - 36s 446ms/step - loss: 0.1732 - accuracy: 0.9431 - val_loss: 0.5070 - val_accuracy: 0.8639
    
    Epoch 00013: val_accuracy improved from 0.85481 to 0.86388, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 14/50
    81/81 [==============================] - 36s 449ms/step - loss: 0.1510 - accuracy: 0.9482 - val_loss: 0.5158 - val_accuracy: 0.8730
    
    Epoch 00014: val_accuracy improved from 0.86388 to 0.87296, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 15/50
    81/81 [==============================] - 36s 444ms/step - loss: 0.1292 - accuracy: 0.9591 - val_loss: 0.4857 - val_accuracy: 0.8548
    
    Epoch 00015: val_accuracy did not improve from 0.87296
    Epoch 16/50
    81/81 [==============================] - 37s 453ms/step - loss: 0.1297 - accuracy: 0.9568 - val_loss: 0.5115 - val_accuracy: 0.8566
    
    Epoch 00016: val_accuracy did not improve from 0.87296
    Epoch 17/50
    81/81 [==============================] - 37s 456ms/step - loss: 0.1206 - accuracy: 0.9560 - val_loss: 0.5111 - val_accuracy: 0.8675
    
    Epoch 00017: val_accuracy did not improve from 0.87296
    Epoch 18/50
    81/81 [==============================] - 37s 451ms/step - loss: 0.1141 - accuracy: 0.9571 - val_loss: 0.5072 - val_accuracy: 0.8748
    
    Epoch 00018: val_accuracy improved from 0.87296 to 0.87477, saving model to model_checkpoints/vgg16_case1.h5
    Epoch 19/50
    81/81 [==============================] - 36s 445ms/step - loss: 0.1206 - accuracy: 0.9595 - val_loss: 0.4995 - val_accuracy: 0.8730
    
    Epoch 00019: val_accuracy did not improve from 0.87477
    Epoch 20/50
    81/81 [==============================] - 37s 451ms/step - loss: 0.1016 - accuracy: 0.9669 - val_loss: 0.5402 - val_accuracy: 0.8693
    
    Epoch 00020: val_accuracy did not improve from 0.87477
    Restoring model weights from the end of the best epoch.
    Epoch 00020: early stopping



```python
# ğŸ”í•™ìŠµ ê²°ê³¼ ì €ì¥
model.save(checkpoint_path)
print(f"âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {checkpoint_path}")
```

    INFO:tensorflow:Assets written to: model_checkpoints/assets
    âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: model_checkpoints



```python
def plot_training_history(history):
    # ì†ì‹¤ê³¼ ì •í™•ë„ ê·¸ë˜í”„ë¥¼ 2x1 êµ¬ì¡°ë¡œ ìƒì„±
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ì†ì‹¤ ê·¸ë˜í”„
    ax1.plot(history_1_0.history['loss'], label='Training Loss')
    ax1.plot(history_1_0.history['val_loss'], label='Validation Loss')
    ax1.set_title('Model Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend(loc='upper right')
    ax1.grid(True)
    
    # ì •í™•ë„ ê·¸ë˜í”„
    ax2.plot(history_1_0.history['accuracy'], label='Training Accuracy')
    ax2.plot(history_1_0.history['val_accuracy'], label='Validation Accuracy')
    ax2.set_title('Model Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend(loc='lower right')
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()

plot_training_history(history_1_0)
print()
    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥
print("\n===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====")
print(f"ìµœì¢… í›ˆë ¨ ì†ì‹¤: {history_1_0.history['loss'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {history_1_0.history['val_loss'][-1]:.4f}")
print(f"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {history_1_0.history['accuracy'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history_1_0.history['val_accuracy'][-1]:.4f}")
```


    
![png](output_14_0.png)
    


    
    
    ===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====
    ìµœì¢… í›ˆë ¨ ì†ì‹¤: 0.0802
    ìµœì¢… ê²€ì¦ ì†ì‹¤: 0.5576
    ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9770
    ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.8748



```python
# ëª¨ë¸ í‰ê°€
print("\n===== ëª¨ë¸ í‰ê°€ =====")
evaluation = model.evaluate(test_generator)
print(f'Test Loss: {evaluation[0]:.4f}')
print(f'Test Accuracy: {evaluation[1]:.4f}')

# ì˜ˆì¸¡ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
from sklearn.metrics import classification_report
import numpy as np

# ì˜ˆì¸¡
predictions = model.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# í´ë˜ìŠ¤ ë ˆì´ë¸”
class_labels = list(test_generator.class_indices.keys())

# ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥
print("\n===== ë¶„ë¥˜ ë³´ê³ ì„œ =====")
print(classification_report(y_true, y_pred, target_names=class_labels))
```

    
    ===== ëª¨ë¸ í‰ê°€ =====
    18/18 [==============================] - 3s 135ms/step - loss: 0.3827 - accuracy: 0.8822
    Test Loss: 0.3827
    Test Accuracy: 0.8822
    
    ===== ë¶„ë¥˜ ë³´ê³ ì„œ =====
                  precision    recall  f1-score   support
    
           daisy       0.91      0.93      0.92        95
       dandelion       0.90      0.90      0.90       135
           roses       0.84      0.88      0.86        97
      sunflowers       0.91      0.88      0.89       105
          tulips       0.86      0.84      0.85       120
    
        accuracy                           0.88       552
       macro avg       0.88      0.88      0.88       552
    weighted avg       0.88      0.88      0.88       552
    


# 4. Traning & Result analysis (Case 2. Data ì¦ê°•)


```python
# 1. í›ˆë ¨ ë°ì´í„°ìš© ImageDataGenerator - ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²• ì ìš©
train_datagen_aug = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=30,              # ì´ë¯¸ì§€ íšŒì „ (0-180ë„)
    width_shift_range=0.2,         # ì¢Œìš° ì´ë™
    height_shift_range=0.2,        # ìƒí•˜ ì´ë™
    brightness_range=[0.8,1.2],    # ë°ê¸° ì¡°ì ˆ
    shear_range=0.2,              # ì „ë‹¨ ë³€í™˜
    zoom_range=0.2,               # í™•ëŒ€/ì¶•ì†Œ
    horizontal_flip=True,         # ì¢Œìš° ë°˜ì „
    vertical_flip=False,          # ìƒí•˜ ë°˜ì „ (ê½ƒ ì´ë¯¸ì§€ëŠ” ìƒí•˜ë°˜ì „ì´ ë¶€ì ì ˆí•  ìˆ˜ ìˆìŒ)
    fill_mode='nearest'          # ë¹ˆ í”½ì…€ ì±„ìš°ê¸° ë°©ì‹
)

# 2. ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ìš© ImageDataGenerator - ì „ì²˜ë¦¬ë§Œ ì ìš©
valid_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

# 3. ë°ì´í„° ë¡œë“œ
train_generator_aug = train_datagen_aug.flow_from_directory(
    directory=train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=True
)

valid_generator = valid_datagen.flow_from_directory(
    directory=valid_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    directory=test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# 4. ì¦ê°•ëœ ì´ë¯¸ì§€ ì‹œê°í™” í•¨ìˆ˜
def visualize_augmented_images(generator, num_images=5):
    """ì¦ê°•ëœ ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    plt.figure(figsize=(20, 4))
    
    # í•˜ë‚˜ì˜ ë°°ì¹˜ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
    x, y = next(generator)
    
    for i in range(num_images):
        plt.subplot(1, num_images, i+1)
        plt.imshow((x[i] + 1) / 2)  # [-1, 1] ë²”ìœ„ë¥¼ [0, 1] ë²”ìœ„ë¡œ ë³€í™˜
        plt.axis('off')
        plt.title(f'Class: {list(train_generator.class_indices.keys())[np.argmax(y[i])]}')
    
    plt.tight_layout()
    plt.show()

# 5. ì¦ê°•ëœ ì´ë¯¸ì§€ í™•ì¸
print("===== ì¦ê°•ëœ ì´ë¯¸ì§€ ì˜ˆì‹œ =====")
visualize_augmented_images(train_generator)

# 6. ê° í´ë˜ìŠ¤ë³„ ì¦ê°•ëœ ì´ë¯¸ì§€ í™•ì¸
def visualize_augmentation_per_class(generator, num_augmentations=5):
    """ê° í´ë˜ìŠ¤ë³„ë¡œ ì¦ê°•ëœ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜"""
    class_names = list(generator.class_indices.keys())
    
    for class_name in class_names:
        print(f"\n=== Class: {class_name} ===")
        
        # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì°¾ê¸°
        for x, y in generator:
            class_indices = np.where(np.argmax(y, axis=1) == generator.class_indices[class_name])[0]
            if len(class_indices) > 0:
                img = x[class_indices[0]]
                break
        
        # ì„ íƒëœ ì´ë¯¸ì§€ì— ëŒ€í•´ ì—¬ëŸ¬ ë²ˆì˜ ì¦ê°• ì ìš©
        plt.figure(figsize=(20, 4))
        plt.subplot(1, num_augmentations+1, 1)
        plt.imshow((img + 1) / 2)
        plt.title('Original')
        plt.axis('off')
        
        for i in range(num_augmentations):
            img_aug = train_datagen.random_transform(img)
            plt.subplot(1, num_augmentations+1, i+2)
            plt.imshow((img_aug + 1) / 2)
            plt.title(f'Augmented {i+1}')
            plt.axis('off')
        
        plt.tight_layout()
        plt.show()

# 7. ê° í´ë˜ìŠ¤ë³„ ì¦ê°• ê²°ê³¼ í™•ì¸
print("\n===== í´ë˜ìŠ¤ë³„ ì¦ê°• ê²°ê³¼ =====")
visualize_augmentation_per_class(train_generator)
```

    Found 2567 images belonging to 5 classes.
    Found 551 images belonging to 5 classes.
    Found 552 images belonging to 5 classes.
    ===== ì¦ê°•ëœ ì´ë¯¸ì§€ ì˜ˆì‹œ =====


    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![png](output_17_2.png)
    


    
    ===== í´ë˜ìŠ¤ë³„ ì¦ê°• ê²°ê³¼ =====
    
    === Class: daisy ===


    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![png](output_17_5.png)
    


    
    === Class: dandelion ===


    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![png](output_17_8.png)
    


    
    === Class: roses ===


    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![png](output_17_11.png)
    


    
    === Class: sunflowers ===


    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![png](output_17_14.png)
    


    
    === Class: tulips ===


    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![png](output_17_17.png)
    



```python
# ëª¨ë¸ í•™ìŠµ
history_2_0 = model.fit(
    train_generator_aug,
    validation_data=valid_generator,
    epochs=50,
    callbacks=callbacks,
    verbose=1
)

# ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ì‹œê°í™” 
plot_training_history(history_2_0)
print()
    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥
print("\n===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====")
print(f"ìµœì¢… í›ˆë ¨ ì†ì‹¤: {history_2_0.history['loss'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {history_2_0.history['val_loss'][-1]:.4f}")
print(f"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {history_2_0.history['accuracy'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history_2_0.history['val_accuracy'][-1]:.4f}")
```

    Epoch 1/50
    81/81 [==============================] - 43s 525ms/step - loss: 0.1317 - accuracy: 0.9533 - val_loss: 0.5648 - val_accuracy: 0.8766
    
    Epoch 00001: val_accuracy did not improve from 0.87840
    Epoch 2/50
    81/81 [==============================] - 43s 531ms/step - loss: 0.1473 - accuracy: 0.9470 - val_loss: 0.5489 - val_accuracy: 0.8621
    
    Epoch 00002: val_accuracy did not improve from 0.87840
    Epoch 3/50
    81/81 [==============================] - 43s 534ms/step - loss: 0.1373 - accuracy: 0.9517 - val_loss: 0.5841 - val_accuracy: 0.8621
    
    Epoch 00003: val_accuracy did not improve from 0.87840
    Epoch 4/50
    81/81 [==============================] - 43s 533ms/step - loss: 0.1241 - accuracy: 0.9560 - val_loss: 0.5810 - val_accuracy: 0.8566
    
    Epoch 00004: val_accuracy did not improve from 0.87840
    Epoch 5/50
    81/81 [==============================] - 43s 531ms/step - loss: 0.1060 - accuracy: 0.9634 - val_loss: 0.5547 - val_accuracy: 0.8730
    
    Epoch 00005: val_accuracy did not improve from 0.87840
    Epoch 6/50
    81/81 [==============================] - 44s 539ms/step - loss: 0.1050 - accuracy: 0.9653 - val_loss: 0.5966 - val_accuracy: 0.8693
    
    Epoch 00006: val_accuracy did not improve from 0.87840
    Epoch 7/50
    81/81 [==============================] - 43s 532ms/step - loss: 0.1188 - accuracy: 0.9575 - val_loss: 0.5955 - val_accuracy: 0.8675
    
    Epoch 00007: val_accuracy did not improve from 0.87840
    Restoring model weights from the end of the best epoch.
    Epoch 00007: early stopping



    
![png](output_18_1.png)
    


    
    
    ===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====
    ìµœì¢… í›ˆë ¨ ì†ì‹¤: 0.1188
    ìµœì¢… ê²€ì¦ ì†ì‹¤: 0.5955
    ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9575
    ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.8675



```python
# ëª¨ë¸ í‰ê°€
print("\n===== ëª¨ë¸ í‰ê°€ =====")
evaluation = model.evaluate(test_generator)
print(f'Test Loss: {evaluation[0]:.4f}')
print(f'Test Accuracy: {evaluation[1]:.4f}')

# ì˜ˆì¸¡ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
from sklearn.metrics import classification_report
import numpy as np

# ì˜ˆì¸¡
predictions = model.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# í´ë˜ìŠ¤ ë ˆì´ë¸”
class_labels = list(test_generator.class_indices.keys())

# ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥
print("\n===== ë¶„ë¥˜ ë³´ê³ ì„œ =====")
print(classification_report(y_true, y_pred, target_names=class_labels))
```

    
    ===== ëª¨ë¸ í‰ê°€ =====
    18/18 [==============================] - 3s 140ms/step - loss: 0.3780 - accuracy: 0.8804
    Test Loss: 0.3780
    Test Accuracy: 0.8804
    
    ===== ë¶„ë¥˜ ë³´ê³ ì„œ =====
                  precision    recall  f1-score   support
    
           daisy       0.91      0.92      0.91        95
       dandelion       0.90      0.91      0.90       135
           roses       0.83      0.86      0.84        97
      sunflowers       0.95      0.85      0.89       105
          tulips       0.83      0.87      0.85       120
    
        accuracy                           0.88       552
       macro avg       0.88      0.88      0.88       552
    weighted avg       0.88      0.88      0.88       552
    


# 5. Traning & Result analysis (Case 3. ì¶”ì¶œì¸µ ê°€ì¤‘ì¹˜ ë™ê²° í•´ì œ)


```python
# ëª¨ë¸ ìƒì„±
def create_model(num_classes):
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu')(x)
    predictions = Dense(num_classes, activation='softmax')(x)
    
    model = Model(inputs=base_model.input, outputs=predictions)
    
    for layer in base_model.layers[:10]:  # ì²˜ìŒ 10ê°œ ì¸µì€ ê³ ì •
        layer.trainable = False
    for layer in base_model.layers[10:]:  # ë‚˜ë¨¸ì§€ ì¸µì€ í•™ìŠµ ê°€ëŠ¥
        layer.trainable = True
    
    return model

# ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼
model_case3 = create_model(num_classes)
model_case3.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# ëª¨ë¸ êµ¬ì¡° í™•ì¸
model_case3.summary()


# ì½œë°± ì •ì˜
callbacks = [
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    ModelCheckpoint(
        filepath=os.path.join(checkpoint_path, 'best_model.h5'),
        monitor='val_accuracy',    # ê²€ì¦ ì •í™•ë„ ëª¨ë‹ˆí„°ë§
        save_best_only=True,      # ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ë§Œ ì €ì¥
        mode='max',               # ì •í™•ë„ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        verbose=1
    ),
    
    # ì¡°ê¸° ì¢…ë£Œ
    EarlyStopping(
        monitor='val_loss',       # ê²€ì¦ ì†ì‹¤ ëª¨ë‹ˆí„°ë§
        patience=5,               # 5ë²ˆì˜ ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ì§€
        restore_best_weights=True,# ê°€ì¥ ì¢‹ì€ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
        verbose=1
    )
]
```

    Model: "model_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_2 (InputLayer)         [(None, 224, 224, 3)]     0         
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         
    _________________________________________________________________
    global_average_pooling2d_1 ( (None, 512)               0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 512)               262656    
    _________________________________________________________________
    dense_3 (Dense)              (None, 5)                 2565      
    =================================================================
    Total params: 14,979,909
    Trainable params: 13,244,421
    Non-trainable params: 1,735,488
    _________________________________________________________________



```python
# ëª¨ë¸ í•™ìŠµ
history_case3 = model_case3.fit(
    train_generator_aug,
    validation_data=valid_generator,
    epochs=50,
    callbacks=callbacks,
    verbose=1
)
```

    Epoch 1/50
    81/81 [==============================] - 47s 533ms/step - loss: 0.8919 - accuracy: 0.6837 - val_loss: 0.7276 - val_accuracy: 0.7659
    
    Epoch 00001: val_accuracy improved from -inf to 0.76588, saving model to model_checkpoints/best_model.h5
    Epoch 2/50
    81/81 [==============================] - 44s 542ms/step - loss: 0.4383 - accuracy: 0.8457 - val_loss: 0.4073 - val_accuracy: 0.8566
    
    Epoch 00002: val_accuracy improved from 0.76588 to 0.85662, saving model to model_checkpoints/best_model.h5
    Epoch 3/50
    81/81 [==============================] - 44s 538ms/step - loss: 0.3384 - accuracy: 0.8804 - val_loss: 0.3753 - val_accuracy: 0.8621
    
    Epoch 00003: val_accuracy improved from 0.85662 to 0.86207, saving model to model_checkpoints/best_model.h5
    Epoch 4/50
    81/81 [==============================] - 44s 540ms/step - loss: 0.2668 - accuracy: 0.9042 - val_loss: 0.4098 - val_accuracy: 0.8693
    
    Epoch 00004: val_accuracy improved from 0.86207 to 0.86933, saving model to model_checkpoints/best_model.h5
    Epoch 5/50
    81/81 [==============================] - 44s 540ms/step - loss: 0.2168 - accuracy: 0.9213 - val_loss: 0.3215 - val_accuracy: 0.8966
    
    Epoch 00005: val_accuracy improved from 0.86933 to 0.89655, saving model to model_checkpoints/best_model.h5
    Epoch 6/50
    81/81 [==============================] - 44s 536ms/step - loss: 0.1843 - accuracy: 0.9346 - val_loss: 0.5885 - val_accuracy: 0.8603
    
    Epoch 00006: val_accuracy did not improve from 0.89655
    Epoch 7/50
    81/81 [==============================] - 45s 558ms/step - loss: 0.1463 - accuracy: 0.9451 - val_loss: 0.4298 - val_accuracy: 0.8911
    
    Epoch 00007: val_accuracy did not improve from 0.89655
    Epoch 8/50
    81/81 [==============================] - 44s 543ms/step - loss: 0.1587 - accuracy: 0.9427 - val_loss: 0.2718 - val_accuracy: 0.9093
    
    Epoch 00008: val_accuracy improved from 0.89655 to 0.90926, saving model to model_checkpoints/best_model.h5
    Epoch 9/50
    81/81 [==============================] - 45s 555ms/step - loss: 0.1426 - accuracy: 0.9536 - val_loss: 0.3280 - val_accuracy: 0.9111
    
    Epoch 00009: val_accuracy improved from 0.90926 to 0.91107, saving model to model_checkpoints/best_model.h5
    Epoch 10/50
    81/81 [==============================] - 44s 541ms/step - loss: 0.1397 - accuracy: 0.9505 - val_loss: 0.3355 - val_accuracy: 0.9111
    
    Epoch 00010: val_accuracy did not improve from 0.91107
    Epoch 11/50
    81/81 [==============================] - 45s 553ms/step - loss: 0.1242 - accuracy: 0.9649 - val_loss: 0.4468 - val_accuracy: 0.8784
    
    Epoch 00011: val_accuracy did not improve from 0.91107
    Epoch 12/50
    81/81 [==============================] - 44s 546ms/step - loss: 0.1175 - accuracy: 0.9579 - val_loss: 0.4796 - val_accuracy: 0.9165
    
    Epoch 00012: val_accuracy improved from 0.91107 to 0.91652, saving model to model_checkpoints/best_model.h5
    Epoch 13/50
    81/81 [==============================] - 44s 545ms/step - loss: 0.1416 - accuracy: 0.9513 - val_loss: 0.4595 - val_accuracy: 0.8766
    
    Epoch 00013: val_accuracy did not improve from 0.91652
    Restoring model weights from the end of the best epoch.
    Epoch 00013: early stopping



```python
# ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ì‹œê°í™” 
plot_training_history(history_case3)
print()
    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥
print("\n===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====")
print(f"ìµœì¢… í›ˆë ¨ ì†ì‹¤: {history_case3.history['loss'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {history_case3.history['val_loss'][-1]:.4f}")
print(f"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {history_case3.history['accuracy'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history_case3.history['val_accuracy'][-1]:.4f}")
```


    
![png](output_23_0.png)
    


    
    
    ===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====
    ìµœì¢… í›ˆë ¨ ì†ì‹¤: 0.1416
    ìµœì¢… ê²€ì¦ ì†ì‹¤: 0.4595
    ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9513
    ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.8766



```python
# ëª¨ë¸ í‰ê°€
print("\n===== ëª¨ë¸ í‰ê°€ =====")
evaluation = model_case3.evaluate(test_generator)
print(f'Test Loss: {evaluation[0]:.4f}')
print(f'Test Accuracy: {evaluation[1]:.4f}')

# ì˜ˆì¸¡ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
from sklearn.metrics import classification_report
import numpy as np

# ì˜ˆì¸¡
predictions = model_case3.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# í´ë˜ìŠ¤ ë ˆì´ë¸”
class_labels = list(test_generator.class_indices.keys())

# ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥
print("\n===== ë¶„ë¥˜ ë³´ê³ ì„œ =====")
print(classification_report(y_true, y_pred, target_names=class_labels))
```

    
    ===== ëª¨ë¸ í‰ê°€ =====
    18/18 [==============================] - 3s 140ms/step - loss: 0.2744 - accuracy: 0.9149
    Test Loss: 0.2744
    Test Accuracy: 0.9149
    
    ===== ë¶„ë¥˜ ë³´ê³ ì„œ =====
                  precision    recall  f1-score   support
    
           daisy       0.97      0.89      0.93        95
       dandelion       0.94      0.97      0.95       135
           roses       0.84      0.89      0.86        97
      sunflowers       0.93      0.95      0.94       105
          tulips       0.90      0.86      0.88       120
    
        accuracy                           0.91       552
       macro avg       0.91      0.91      0.91       552
    weighted avg       0.92      0.91      0.91       552
    


# 6. Traning & Result analysis (Case 4. í•™ìŠµë¥  ì†ì‹¤)


```python
# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©
def schedule(epoch):
    initial_lr = 0.0001
    drop = 0.5
    epochs_drop = 5.0
    lr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))
    return lr

# ì»´íŒŒì¼ ì‹œ ì½œë°± ì¶”ê°€
lr_scheduler = LearningRateScheduler(schedule)

# ì½œë°± ì •ì˜
callbacks = [
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    ModelCheckpoint(
        filepath=os.path.join(checkpoint_path, 'best_model.h5'),
        monitor='val_accuracy',    # ê²€ì¦ ì •í™•ë„ ëª¨ë‹ˆí„°ë§
        save_best_only=True,      # ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ë§Œ ì €ì¥
        mode='max',               # ì •í™•ë„ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        verbose=1
    ),
    
    # ì¡°ê¸° ì¢…ë£Œ
    EarlyStopping(
        monitor='val_loss',       # ê²€ì¦ ì†ì‹¤ ëª¨ë‹ˆí„°ë§
        patience=5,               # 5ë²ˆì˜ ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ì§€
        restore_best_weights=True,# ê°€ì¥ ì¢‹ì€ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
        verbose=1
    ),
    
    # í•™ìŠµë¥  ì¡°ì •
    lr_scheduler
]

# ëª¨ë¸ í•™ìŠµ
history_case4 = model_case3.fit(
    train_generator_aug,
    validation_data=valid_generator,
    epochs=50,
    callbacks=callbacks,
    verbose=1
)
```

    Epoch 1/50
    81/81 [==============================] - 45s 559ms/step - loss: 0.1424 - accuracy: 0.9552 - val_loss: 0.4541 - val_accuracy: 0.8621
    
    Epoch 00001: val_accuracy improved from -inf to 0.86207, saving model to model_checkpoints/best_model.h5
    Epoch 2/50
    81/81 [==============================] - 45s 551ms/step - loss: 0.1359 - accuracy: 0.9509 - val_loss: 0.4051 - val_accuracy: 0.9147
    
    Epoch 00002: val_accuracy improved from 0.86207 to 0.91470, saving model to model_checkpoints/best_model.h5
    Epoch 3/50
    81/81 [==============================] - 45s 548ms/step - loss: 0.1275 - accuracy: 0.9536 - val_loss: 0.3559 - val_accuracy: 0.8966
    
    Epoch 00003: val_accuracy did not improve from 0.91470
    Epoch 4/50
    81/81 [==============================] - 45s 549ms/step - loss: 0.1925 - accuracy: 0.9381 - val_loss: 0.4426 - val_accuracy: 0.8784
    
    Epoch 00004: val_accuracy did not improve from 0.91470
    Epoch 5/50
    81/81 [==============================] - 44s 543ms/step - loss: 0.0772 - accuracy: 0.9731 - val_loss: 0.3345 - val_accuracy: 0.9238
    
    Epoch 00005: val_accuracy improved from 0.91470 to 0.92377, saving model to model_checkpoints/best_model.h5
    Epoch 6/50
    81/81 [==============================] - 44s 542ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 0.4436 - val_accuracy: 0.9183
    
    Epoch 00006: val_accuracy did not improve from 0.92377
    Epoch 7/50
    81/81 [==============================] - 44s 543ms/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.3480 - val_accuracy: 0.9147
    
    Epoch 00007: val_accuracy did not improve from 0.92377
    Epoch 8/50
    81/81 [==============================] - 44s 543ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.2519 - val_accuracy: 0.9365
    
    Epoch 00008: val_accuracy improved from 0.92377 to 0.93648, saving model to model_checkpoints/best_model.h5
    Epoch 9/50
    81/81 [==============================] - 44s 538ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.3234 - val_accuracy: 0.9401
    
    Epoch 00009: val_accuracy improved from 0.93648 to 0.94011, saving model to model_checkpoints/best_model.h5
    Epoch 10/50
    81/81 [==============================] - 44s 537ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.2908 - val_accuracy: 0.9474
    
    Epoch 00010: val_accuracy improved from 0.94011 to 0.94737, saving model to model_checkpoints/best_model.h5
    Epoch 11/50
    81/81 [==============================] - 44s 536ms/step - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.2870 - val_accuracy: 0.9401
    
    Epoch 00011: val_accuracy did not improve from 0.94737
    Epoch 12/50
    81/81 [==============================] - 44s 538ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.2757 - val_accuracy: 0.9528
    
    Epoch 00012: val_accuracy improved from 0.94737 to 0.95281, saving model to model_checkpoints/best_model.h5
    Epoch 13/50
    81/81 [==============================] - 44s 542ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.3487 - val_accuracy: 0.9419
    
    Epoch 00013: val_accuracy did not improve from 0.95281
    Restoring model weights from the end of the best epoch.
    Epoch 00013: early stopping



```python
# ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ì‹œê°í™” 
plot_training_history(history_case4)
print()
    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥
print("\n===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====")
print(f"ìµœì¢… í›ˆë ¨ ì†ì‹¤: {history_case4.history['loss'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {history_case4.history['val_loss'][-1]:.4f}")
print(f"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {history_case4.history['accuracy'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history_case4.history['val_accuracy'][-1]:.4f}")
```


    
![png](output_27_0.png)
    


    
    
    ===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====
    ìµœì¢… í›ˆë ¨ ì†ì‹¤: 0.0128
    ìµœì¢… ê²€ì¦ ì†ì‹¤: 0.3487
    ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9973
    ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.9419



```python
# ëª¨ë¸ í‰ê°€
print("\n===== ëª¨ë¸ í‰ê°€ =====")
evaluation = model_case3.evaluate(test_generator)
print(f'Test Loss: {evaluation[0]:.4f}')
print(f'Test Accuracy: {evaluation[1]:.4f}')

# ì˜ˆì¸¡ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
from sklearn.metrics import classification_report
import numpy as np

# ì˜ˆì¸¡
predictions = model_case3.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# í´ë˜ìŠ¤ ë ˆì´ë¸”
class_labels = list(test_generator.class_indices.keys())

# ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥
print("\n===== ë¶„ë¥˜ ë³´ê³ ì„œ =====")
print(classification_report(y_true, y_pred, target_names=class_labels))
```

    
    ===== ëª¨ë¸ í‰ê°€ =====
    18/18 [==============================] - 3s 134ms/step - loss: 0.3712 - accuracy: 0.9257
    Test Loss: 0.3712
    Test Accuracy: 0.9257
    
    ===== ë¶„ë¥˜ ë³´ê³ ì„œ =====
                  precision    recall  f1-score   support
    
           daisy       0.93      0.95      0.94        95
       dandelion       0.95      0.96      0.96       135
           roses       0.87      0.90      0.88        97
      sunflowers       0.94      0.95      0.95       105
          tulips       0.93      0.87      0.90       120
    
        accuracy                           0.93       552
       macro avg       0.92      0.93      0.92       552
    weighted avg       0.93      0.93      0.93       552
    


# 7. Traning & Result analysis (Case 5. ê°€ì¤‘ì¹˜ ì†ì‹¤)


```python
def create_model_with_weight_decay(num_classes, weight_decay=1e-3):# ì¤‘ê°„ í¬ê¸° ë°ì´í„°ì…‹ì— ì í•©í•œ decay ê°’ìœ¼ë¡œ í•¨
    
    # VGG16 ê¸°ë³¸ ëª¨ë¸ ìƒì„±
    base_model = VGG16(weights='imagenet', 
                      include_top=False, 
                      input_shape=(224, 224, 3))
    
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    
    # Dense ì¸µì— weight decay ì ìš©
    x = Dense(512, 
             activation='relu',
             kernel_regularizer=l2(weight_decay),
             bias_regularizer=l2(weight_decay))(x)
    
    # ì¶œë ¥ì¸µì—ë„ weight decay ì ìš©
    predictions = Dense(num_classes, 
                      activation='softmax',
                      kernel_regularizer=l2(weight_decay),
                      bias_regularizer=l2(weight_decay))(x)
    
    model = Model(inputs=base_model.input, outputs=predictions)
    
    # VGG16 ê¸°ë³¸ ì¸µë“¤ì—ë„ ê°€ì¤‘ì¹˜ í•™ìŠµ ê°€ëŠ¥í† ë¡, weight decay ì ìš© 
    for layer in base_model.layers[:10]:  # ì²˜ìŒ 10ê°œ ì¸µì€ ê³ ì •
        layer.trainable = False
    for layer in base_model.layers[10:]:  # ë‚˜ë¨¸ì§€ ì¸µì€ í•™ìŠµ ê°€ëŠ¥
        layer.trainable = True
    
    for layer in base_model.layers:       # weight decay ì ìš© 
        if isinstance(layer, tf.keras.layers.Conv2D):
            layer.kernel_regularizer = l2(weight_decay)
            layer.bias_regularizer = l2(weight_decay)
    
    return model

# ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼
model_case5 = create_model_with_weight_decay(num_classes=5, weight_decay=1e-3)

# Adam ì˜µí‹°ë§ˆì´ì €ì— weight decay ì ìš© (AdamW)
optimizer = tfa.optimizers.AdamW(
    learning_rate=0.0001,
    weight_decay=0.0001
)

# ëª¨ë¸ ì»´íŒŒì¼
model_case5.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# ëª¨ë¸ êµ¬ì¡° í™•ì¸
model_case5.summary()

```

    Model: "model_2"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_3 (InputLayer)         [(None, 224, 224, 3)]     0         
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         
    _________________________________________________________________
    global_average_pooling2d_2 ( (None, 512)               0         
    _________________________________________________________________
    dense_4 (Dense)              (None, 512)               262656    
    _________________________________________________________________
    dense_5 (Dense)              (None, 5)                 2565      
    =================================================================
    Total params: 14,979,909
    Trainable params: 13,244,421
    Non-trainable params: 1,735,488
    _________________________________________________________________



```python
# ì½œë°± ì •ì˜
callbacks = [
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    ModelCheckpoint(
        filepath=os.path.join(checkpoint_path, 'best_model.h5'),
        monitor='val_accuracy',    # ê²€ì¦ ì •í™•ë„ ëª¨ë‹ˆí„°ë§
        save_best_only=True,      # ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ë§Œ ì €ì¥
        mode='max',               # ì •í™•ë„ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        verbose=1
    ),
    
    # ì¡°ê¸° ì¢…ë£Œ
    EarlyStopping(
        monitor='val_loss',       # ê²€ì¦ ì†ì‹¤ ëª¨ë‹ˆí„°ë§
        patience=5,               # 5ë²ˆì˜ ì—í¬í¬ ë™ì•ˆ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ì§€
        restore_best_weights=True,# ê°€ì¥ ì¢‹ì€ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
        verbose=1
    ),
    
    # í•™ìŠµë¥  ì¡°ì •
    lr_scheduler
]

# ëª¨ë¸ í•™ìŠµ
history_case5 = model_case5.fit(
    train_generator_aug,
    validation_data=valid_generator,
    epochs=50,
    callbacks=callbacks,
    verbose=1
)
```

    Epoch 1/50
    81/81 [==============================] - 45s 541ms/step - loss: 1.2472 - accuracy: 0.7503 - val_loss: 1.0372 - val_accuracy: 0.8221
    
    Epoch 00001: val_accuracy improved from -inf to 0.82214, saving model to model_checkpoints/best_model.h5
    Epoch 2/50
    81/81 [==============================] - 45s 558ms/step - loss: 0.8927 - accuracy: 0.8668 - val_loss: 0.8529 - val_accuracy: 0.8802
    
    Epoch 00002: val_accuracy improved from 0.82214 to 0.88022, saving model to model_checkpoints/best_model.h5
    Epoch 3/50
    81/81 [==============================] - 47s 581ms/step - loss: 0.7752 - accuracy: 0.8929 - val_loss: 0.9160 - val_accuracy: 0.8639
    
    Epoch 00003: val_accuracy did not improve from 0.88022
    Epoch 4/50
    81/81 [==============================] - 44s 536ms/step - loss: 0.7557 - accuracy: 0.8999 - val_loss: 0.8715 - val_accuracy: 0.8748
    
    Epoch 00004: val_accuracy did not improve from 0.88022
    Epoch 5/50
    81/81 [==============================] - 44s 539ms/step - loss: 0.6307 - accuracy: 0.9404 - val_loss: 0.7901 - val_accuracy: 0.9056
    
    Epoch 00005: val_accuracy improved from 0.88022 to 0.90563, saving model to model_checkpoints/best_model.h5
    Epoch 6/50
    81/81 [==============================] - 44s 541ms/step - loss: 0.5598 - accuracy: 0.9646 - val_loss: 0.8104 - val_accuracy: 0.9038
    
    Epoch 00006: val_accuracy did not improve from 0.90563
    Epoch 7/50
    81/81 [==============================] - 43s 535ms/step - loss: 0.5632 - accuracy: 0.9622 - val_loss: 0.7884 - val_accuracy: 0.8947
    
    Epoch 00007: val_accuracy did not improve from 0.90563
    Epoch 8/50
    81/81 [==============================] - 44s 552ms/step - loss: 0.5362 - accuracy: 0.9661 - val_loss: 0.8012 - val_accuracy: 0.8929
    
    Epoch 00008: val_accuracy did not improve from 0.90563
    Epoch 9/50
    81/81 [==============================] - 43s 534ms/step - loss: 0.5062 - accuracy: 0.9735 - val_loss: 0.8911 - val_accuracy: 0.8984
    
    Epoch 00009: val_accuracy did not improve from 0.90563
    Epoch 10/50
    81/81 [==============================] - 43s 534ms/step - loss: 0.4767 - accuracy: 0.9825 - val_loss: 0.8137 - val_accuracy: 0.9165
    
    Epoch 00010: val_accuracy improved from 0.90563 to 0.91652, saving model to model_checkpoints/best_model.h5
    Epoch 11/50
    81/81 [==============================] - 44s 538ms/step - loss: 0.4563 - accuracy: 0.9891 - val_loss: 0.8455 - val_accuracy: 0.9147
    
    Epoch 00011: val_accuracy did not improve from 0.91652
    Epoch 12/50
    81/81 [==============================] - 45s 558ms/step - loss: 0.4430 - accuracy: 0.9930 - val_loss: 0.8183 - val_accuracy: 0.9274
    
    Epoch 00012: val_accuracy improved from 0.91652 to 0.92740, saving model to model_checkpoints/best_model.h5
    Restoring model weights from the end of the best epoch.
    Epoch 00012: early stopping



```python
# ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ì‹œê°í™” 
plot_training_history(history_case5)
print()
    # ìµœì¢… ì„±ëŠ¥ ì¶œë ¥
print("\n===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====")
print(f"ìµœì¢… í›ˆë ¨ ì†ì‹¤: {history_case5.history['loss'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì†ì‹¤: {history_case5.history['val_loss'][-1]:.4f}")
print(f"ìµœì¢… í›ˆë ¨ ì •í™•ë„: {history_case5.history['accuracy'][-1]:.4f}")
print(f"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history_case5.history['val_accuracy'][-1]:.4f}")
```


    
![png](output_32_0.png)
    


    
    
    ===== ìµœì¢… í•™ìŠµ ê²°ê³¼ =====
    ìµœì¢… í›ˆë ¨ ì†ì‹¤: 0.4430
    ìµœì¢… ê²€ì¦ ì†ì‹¤: 0.8183
    ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9930
    ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.9274



```python
# ëª¨ë¸ í‰ê°€
print("\n===== ëª¨ë¸ í‰ê°€ =====")
evaluation = model_case5.evaluate(test_generator)
print(f'Test Loss: {evaluation[0]:.4f}')
print(f'Test Accuracy: {evaluation[1]:.4f}')

# ì˜ˆì¸¡ ë° ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
from sklearn.metrics import classification_report
import numpy as np

# ì˜ˆì¸¡
predictions = model_case5.predict(test_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# í´ë˜ìŠ¤ ë ˆì´ë¸”
class_labels = list(test_generator.class_indices.keys())

# ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥
print("\n===== ë¶„ë¥˜ ë³´ê³ ì„œ =====")
print(classification_report(y_true, y_pred, target_names=class_labels))
```

    
    ===== ëª¨ë¸ í‰ê°€ =====
    18/18 [==============================] - 3s 135ms/step - loss: 0.9487 - accuracy: 0.8859
    Test Loss: 0.9487
    Test Accuracy: 0.8859
    
    ===== ë¶„ë¥˜ ë³´ê³ ì„œ =====
                  precision    recall  f1-score   support
    
           daisy       0.93      0.82      0.87        95
       dandelion       0.98      0.90      0.94       135
           roses       0.93      0.76      0.84        97
      sunflowers       0.86      0.96      0.91       105
          tulips       0.78      0.95      0.85       120
    
        accuracy                           0.89       552
       macro avg       0.90      0.88      0.88       552
    weighted avg       0.90      0.89      0.89       552
    


# 8. ê²°ê³¼ ìš”ì•½

Case1. ê¸°ë³¸ ëª¨ë¸ : í›ˆë ¨ ì •í™•ë„ (97.70%), ê²€ì¦ ì •í™•ë„ (87.48%), í…ŒìŠ¤íŠ¸ ì •í™•ë„ (88.22%)

Case2. ë°ì´í„° ì¦ê°•: í›ˆë ¨ ì •í™•ë„ (95.75%), ê²€ì¦ ì •í™•ë„ (86.75%), í…ŒìŠ¤íŠ¸ ì •í™•ë„ (88.04%)

Case3. ì¶”ì¶œì¸µ ê°€ì¤‘ì¹˜ ë™ê²° í•´ì œ: í›ˆë ¨ ì •í™•ë„ (95.13%), ê²€ì¦ ì •í™•ë„ (87.66%), í…ŒìŠ¤íŠ¸ ì •í™•ë„ (91.49%)

Case4. í•™ìŠµë¥ ì„ ì¡°ì •í•˜ëŠ” ê²½ìš° (step decay): í›ˆë ¨ ì •í™•ë„ (99.73%), ê²€ì¦ ì •í™•ë„ (94.19%), í…ŒìŠ¤íŠ¸ ì •í™•ë„ (92.57%)

Case5. ê°€ì¤‘ì¹˜ ì†ì‹¤ (weight decay): í›ˆë ¨ ì •í™•ë„ (99.30%), ê²€ì¦ ì •í™•ë„ (92.2074%), í…ŒìŠ¤íŠ¸ ì •í™•ë„ (88.59%)

# 9. ê¸°ë³¸ ëª¨ë¸ ìƒìš©í™” ì¤€ë¹„


```python
# ëª¨ë¸ ìƒìš©í™”

def show_and_predict_image(filename, img_size=224, class_indices=None):
    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    BASE_DIR = '/aiffel/aiffel/datasets/sunflower_test'
    
    if class_indices is None:
        # ê¸°ë³¸ í´ë˜ìŠ¤ ì •ì˜
        class_indices = {
            'dandelion': 0,
            'daisy': 1,
            'sunflower': 2,
            'rose': 3,
            'tulip': 4
        }
    
    # í´ë˜ìŠ¤ ì´ë¦„ê³¼ ì¸ë±ìŠ¤ ë§¤í•‘ ë°˜ì „
    idx_to_class = {v: k for k, v in class_indices.items()}
    
    # ì „ì²´ íŒŒì¼ ê²½ë¡œ ìƒì„±
    filepath = os.path.join(BASE_DIR, filename)
    
   
    # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    try:
        image = load_img(filepath, target_size=(img_size, img_size))
        image_array = img_to_array(image)
        image_array = np.expand_dims(image_array, axis=0)
        image_array = image_array / 255.0
        
        # ì´ë¯¸ì§€ ì¶œë ¥
        plt.figure(figsize=(8, 8))
        plt.imshow(image)
        plt.axis('off')
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = model.predict(image_array)
        predicted_class = np.argmax(predictions[0])
        confidence = predictions[0][predicted_class] * 100
        
        # ê²°ê³¼ ì¶œë ¥
        class_name = idx_to_class[predicted_class]
        print(f"\nì˜ˆì¸¡ ê²°ê³¼: {class_name} ({confidence:.2f}%)")
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
```


```python
show_and_predict_image('sunflower_1.jpg')
```

    ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ: /aiffel/aiffel/datasets/sunflower_test/sunflower_1.jpg
    
    ì˜ˆì¸¡ ê²°ê³¼: dandelion (32.56%)



    
![png](output_38_1.png)
    



```python
show_and_predict_image('sunflower_2.jpg')
```

    ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ: /aiffel/aiffel/datasets/sunflower_test/sunflower_2.jpg
    
    ì˜ˆì¸¡ ê²°ê³¼: dandelion (38.01%)



    
![png](output_39_1.png)
    



```python
show_and_predict_image('sunflower_3.jpg')
```

    ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ: /aiffel/aiffel/datasets/sunflower_test/sunflower_3.jpg
    
    ì˜ˆì¸¡ ê²°ê³¼: daisy (30.58%)



    
![png](output_40_1.png)
    



```python
show_and_predict_image('sunflower_4.jpg')
```

    ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ: /aiffel/aiffel/datasets/sunflower_test/sunflower_4.jpg
    
    ì˜ˆì¸¡ ê²°ê³¼: dandelion (29.62%)



    
![png](output_41_1.png)
    



```python
show_and_predict_image('10386540696_0a95ee53a8_n.jpg')
```

    
    ì˜ˆì¸¡ ê²°ê³¼: dandelion (32.55%)



    
![png](output_42_1.png)
    



```python
show_and_predict_image('9681915384_b3b646dc92_m.jpg')
```

    
    ì˜ˆì¸¡ ê²°ê³¼: sunflower (26.41%)



    
![png](output_43_1.png)
    



```python
show_and_predict_image('12282924083_fb80aa17d4_n_sunflower.jpg')
```

    
    ì˜ˆì¸¡ ê²°ê³¼: dandelion (28.19%)



    
![png](output_44_1.png)
    
# 10. í”ŒëŸ¬í„° ì•± êµ¬í˜„

ì„±ê³µí•˜ì§€ ëª»í•¨


# 11. íšŒê³ 

Flutter ì•±ì€ ì•ˆíƒ€ê¹ê²Œë„ êµ¬í˜„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. API ì—°ê²°ì´ë¼ëŠ” ì²«ë²ˆì§¸ ê±¸ë¦¼ëŒì„ ë„˜ì§ˆ ëª»í–ˆìŠµë‹ˆë‹¤. ê³¼ì—° ë‹¤ìŒë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì„±ê³µí•  ìˆ˜ ìˆì„ëŸ°ì§€ ì—¬ì „íˆ ìì‹ ì´ ì—†ìŠµë‹ˆë‹¤. 
